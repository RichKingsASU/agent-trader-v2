import os
import datetime as dt
import logging
import time
from typing import Any, Callable, Optional, TypeVar

import requests
from zoneinfo import ZoneInfo
T = TypeVar("T")

from alpaca_env import load_alpaca_env

# --- Standard Header ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

DB_URL = os.environ.get("DATABASE_URL")
alpaca = load_alpaca_env()
KEY = alpaca.key_id
SEC = alpaca.secret_key
SYMS = os.environ.get("ALPACA_SYMBOLS", "SPY,IWM,QQQ").split(",")
FEED = os.environ.get("ALPACA_FEED", "iex")
BASE = alpaca.data_stocks_base_v2
HDRS = {"APCA-API-KEY-ID": KEY, "APCA-API-SECRET-KEY": SEC}
# --- End Standard Header ---

def _get_market_session(timestamp_utc: dt.datetime) -> str:
    """
    Classify a UTC timestamp into a market session for America/New_York.
    """
    if not timestamp_utc.tzinfo:
        timestamp_utc = timestamp_utc.replace(tzinfo=ZoneInfo("UTC"))

    ts_ny = timestamp_utc.astimezone(ZoneInfo("America/New_York"))
    t_ny = ts_ny.time()

    pre_market_start = dt.time(4, 0)
    market_open = dt.time(9, 30)
    market_close = dt.time(16, 0)
    after_market_end = dt.time(20, 0)

    # Weekday check (Monday=0, Sunday=6)
    if ts_ny.weekday() >= 5:
        return "CLOSED"

    if pre_market_start <= t_ny < market_open:
        return "PRE"
    if market_open <= t_ny < market_close:
        return "REGULAR"
    if market_close <= t_ny < after_market_end:
        return "AFTER"
    return "CLOSED"


def _retry(fn: Callable[[], T], *, attempts: int = 5, base_sleep_s: float = 1.0) -> T:
    last_err: Optional[BaseException] = None
    for i in range(attempts):
        try:
            return fn()
        except Exception as e:
            last_err = e
            sleep_s = min(base_sleep_s * (2**i), 10.0)
            time.sleep(sleep_s)
    assert last_err is not None
    raise last_err


def fetch_bars(sym, limit=100):
    """Fetches the last N bars for a symbol."""
    url = f"{BASE}/{sym}/bars"
    params = {"timeframe": "1Min", "limit": limit, "feed": FEED, "adjustment": "all"}

    def _do():
        r = requests.get(url, headers=HDRS, params=params, timeout=30)
        r.raise_for_status()
        return r.json().get("bars", [])

    try:
        return _retry(_do)
    except requests.exceptions.RequestException as e:
        logger.error(f"Error fetching bars for {sym}: {e}")
        raise


def _connect_db(db_url: str):
    """
    Lazily import a DB driver only when DATABASE_URL is set.
    Prefer psycopg2 for compatibility with existing schema scripts.
    """
    try:
        import psycopg2  # type: ignore
    except Exception as e:  # pragma: no cover
        raise RuntimeError(
            "DATABASE_URL is set but psycopg2 is not installed in this environment. "
            "Install it (e.g. pip install psycopg2-binary) or unset DATABASE_URL for API-only mode."
        ) from e
    return psycopg2.connect(db_url)

def upsert_bars(conn, sym, bars) -> int:
    """Upserts a list of bars for a given symbol into the database."""
    if not bars:
        return 0

    # Import only when we actually upsert.
    from psycopg2.extras import execute_values  # type: ignore

    rows = []
    for b in bars:
        try:
            ts = dt.datetime.fromisoformat(b["t"].replace("Z", "+00:00"))
            session = _get_market_session(ts)
            o, h, l, c, v = b.get("o"), b.get("h"), b.get("l"), b.get("c"), b.get("v")
            # public.market_data_1m has NOT NULL columns; skip incomplete bars.
            if o is None or h is None or l is None or c is None or v is None:
                logger.warning(f"Skipping incomplete bar for {sym} at ts {b.get('t')}")
                continue
            rows.append(
                (
                    sym,
                    ts,
                    o,
                    h,
                    l,
                    c,
                    int(v),
                    session,
                )
            )
        except (TypeError, ValueError) as e:
            logger.warning(f"Skipping malformed bar for {sym} at ts {b.get('t')}: {e}")
            continue
    
    if not rows:
        return 0

    try:
        with conn.cursor() as cur:
            execute_values(cur, """
                INSERT INTO public.market_data_1m (symbol, ts, open, high, low, close, volume, session)
                VALUES %s
                ON CONFLICT (ts, symbol) DO UPDATE
                  SET open=EXCLUDED.open, high=EXCLUDED.high, low=EXCLUDED.low,
                      close=EXCLUDED.close, volume=EXCLUDED.volume, session=EXCLUDED.session;
            """, rows)
        conn.commit()
        return len(rows)
    except Exception as e:
        logger.error(f"Database error during upsert for {sym}: {e}")
        conn.rollback()
        return 0

def main():
    """Main function to fetch and upsert bars for all symbols."""
    logger.info("Starting short-window ingest for symbols: %s", ", ".join(SYMS))
    total_upserted = 0
    # API-only mode for Cloud Shell / local smoke tests.
    if not DB_URL:
        for s in SYMS:
            bars = fetch_bars(s, limit=5)
            logger.info("%s: fetched %d bars (API-only mode; DATABASE_URL not set)", s, len(bars))
        logger.info("Short-window ingest finished (API-only mode).")
        return

    try:
        with _connect_db(DB_URL) as conn:
            for s in SYMS:
                bars = fetch_bars(s)
                upserted_count = upsert_bars(conn, s, bars)
                logger.info(f"{s}: upserted {upserted_count} bars")
                total_upserted += upserted_count
    except Exception as e:
        logger.critical(f"Bars ingest failed: {e}")
        raise
    finally:
        logger.info(f"Short-window ingest finished. Total bars upserted: {total_upserted}")

if __name__ == "__main__":
    main()
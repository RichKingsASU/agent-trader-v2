name: CI

on:
  pull_request:
  push:
    branches:
      - main
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: TypeScript typecheck gate (packages/shared-types)
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: TypeScript typecheck (shared-types)
        shell: bash
        run: |
          set -euo pipefail
          # No lockfile / workspace root; keep this fast and hermetic by running tsc via npx.
          npx -y --package typescript@5.6.3 tsc -p packages/shared-types/tsconfig.json --noEmit

      - name: "Blockers: banned vendor refs + secret patterns"
        shell: bash
        run: |
          set -euo pipefail

          echo "Scanning tracked files for banned vendor references..."
          if git grep -n -I -i \
            -e "supa[b]ase" \
            -e "SUPA[B]ASE_" \
            -e "VITE_SUPA[B]ASE" \
            -e "@supa[b]ase" \
            -e "postg[re]st" \
            -e "go[tr]ue" \
            -- . ":(exclude).github/workflows/**"; then
            echo "ERROR: banned vendor reference detected." >&2
            exit 1
          fi

          echo "Scanning tracked files for secret markers..."
          if git grep -n -I -E \
            -e "-----BEGIN( [A-Z]+)? PRIVATE KEY-----" \
            -e "\"type\"[[:space:]]*:[[:space:]]*\"service_account\"" \
            -e "\"client_email\"[[:space:]]*:" \
            -e "\"private_key\"[[:space:]]*:" \
            -e "\"private_key_id\"[[:space:]]*:" \
            -- . ":(exclude).github/workflows/**"; then
            echo "ERROR: possible secret material detected." >&2
            exit 1
          fi

      - name: YAML syntax validation (no schema; no cloud calls)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install --upgrade pyyaml
          python - <<'PY'
          from __future__ import annotations
          import sys
          from pathlib import Path
          import yaml

          roots = ["config", "configs", ".github/workflows", "infra", "k8s"]
          files: list[Path] = []
          for r in roots:
            p = Path(r)
            if p.exists():
              files.extend(sorted(p.rglob("*.yml")))
              files.extend(sorted(p.rglob("*.yaml")))

          bad: list[tuple[str, str]] = []
          for f in files:
            try:
              txt = f.read_text(encoding="utf-8", errors="replace")
              list(yaml.safe_load_all(txt))
            except Exception as e:  # noqa: BLE001
              bad.append((str(f), str(e)))

          if bad:
            for f, e in bad[:50]:
              print(f"ERROR: YAML parse failed: {f}: {e}", file=sys.stderr)
            raise SystemExit(2)

          print(f"ok: parsed {len(files)} YAML files")
          PY

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: pip
          cache-dependency-path: |
            backend/requirements.lock
            cloudrun_ingestor/requirements.txt
            cloudrun_consumer/requirements.txt

      - name: Install backend dependencies (locked)
        run: |
          python3 -m pip install --upgrade "pip==24.3.1"
          python3 -m pip install -r backend/requirements.lock

      - name: Install vm_ingest minimal dependencies
        shell: bash
        run: |
          set -euo pipefail
          python3 -m pip install -r backend/ingestion/requirements.txt

      - name: YAML syntax validation (no kubectl)
        shell: bash
        run: |
          set -euo pipefail
          python3 - <<'PY'
          from __future__ import annotations

          from pathlib import Path
          import sys

          try:
              import yaml  # type: ignore
          except Exception as e:
              print(f"ERROR: PyYAML not available: {e}", file=sys.stderr)
              raise SystemExit(2)

          repo = Path(".").resolve()

          # Keep this intentionally scoped: validate YAML we own and expect to be valid,
          # without requiring kubectl/kube schemas or any cloud tooling.
          search_roots = [
              repo / ".github",
              repo / "config",
              repo / "configs",
              repo / "infra",
              repo / "k8s",
              repo / "ops",
          ]

          files: list[Path] = []
          for root in search_roots:
              if root.exists():
                  files.extend(root.rglob("*.yml"))
                  files.extend(root.rglob("*.yaml"))

          # Repo-root Cloud Build configs (cloudbuild*.yaml / cloudbuild*.yml)
          files.extend(repo.glob("cloudbuild*.yml"))
          files.extend(repo.glob("cloudbuild*.yaml"))

          # De-dupe + stable order
          uniq = sorted({p.resolve() for p in files})

          errors: list[tuple[Path, str]] = []
          for p in uniq:
              if ".git" in p.parts:
                  continue
              try:
                  txt = p.read_text(encoding="utf-8", errors="replace")
                  # Parse all docs; ensure each doc is syntactically valid YAML.
                  for _doc in yaml.safe_load_all(txt):
                      pass
              except Exception as e:  # noqa: BLE001 - report parse errors cleanly
                  rel = p.relative_to(repo)
                  errors.append((rel, f"{type(e).__name__}: {e}"))

          if errors:
              print("ERROR: YAML validation failed:", file=sys.stderr)
              for rel, msg in errors:
                  print(f" - {rel}: {msg}", file=sys.stderr)
              raise SystemExit(1)

          print(f"OK: YAML parsed successfully ({len(uniq)} files).")
          PY

      - name: Validate Cloud Build configs (immutability + presence)
        shell: bash
        run: bash scripts/validate_cloudbuild_configs.sh

      - name: Validate CI layout references (Cloud Build script paths)
        shell: bash
        run: bash scripts/validate_ci_layout.sh

      - name: CI safety guard (read-only)
        shell: bash
        run: bash scripts/ci_safety_guard.sh

      - name: Python import smoke checks
        shell: bash
        run: python3 scripts/smoke_check_imports.py

      - name: Pre-build Python import test (cloudrun_ingestor)
        shell: bash
        run: |
          set -euo pipefail
          python3 -m pip install -r cloudrun_ingestor/requirements.txt
          python3 -m pip install -q --upgrade pytest
          python3 -m pytest -q tests/test_imports.py

          # Import the actual Cloud Run entrypoint with dummy env to ensure we catch:
          # - missing dependencies
          # - syntax / import errors
          # - accidental early-exit on startup
          GCP_PROJECT_ID=dummy \
          SYSTEM_EVENTS_TOPIC=dummy \
          MARKET_TICKS_TOPIC=dummy \
          MARKET_BARS_1M_TOPIC=dummy \
          TRADE_SIGNALS_TOPIC=dummy \
          INGEST_FLAG_SECRET_ID=dummy \
          python3 -c "import importlib.util; s=importlib.util.spec_from_file_location('cloudrun_ingestor_main','cloudrun_ingestor/main.py'); m=importlib.util.module_from_spec(s); s.loader.exec_module(m); print('ok: imported cloudrun_ingestor/main.py')"

      - name: Pre-build Python import test (cloudrun_consumer; package-safe imports)
        shell: bash
        run: |
          set -euo pipefail
          python3 -m pip install -r cloudrun_consumer/requirements.txt
          python3 -m pip install -q --upgrade pytest

          # Run the service-local unit tests (fast, no cloud calls).
          python3 -m pytest -q cloudrun_consumer/tests

          # Critical: ensure imports do not rely on implicit cwd / flattened imports.
          # Simulate container layout: PYTHONPATH=/app (repo root) + run from a non-repo cwd.
          (cd /tmp && \
            PYTHONPATH="${GITHUB_WORKSPACE}" \
            GCP_PROJECT=dummy \
            SYSTEM_EVENTS_TOPIC=dummy \
            INGEST_FLAG_SECRET_ID=dummy \
            ENV=dummy \
            python3 -c "import cloudrun_consumer.main; print('ok: imported cloudrun_consumer.main')"
          )

      - name: Docker build + boot smoke test (cloudrun_ingestor)
        shell: bash
        run: |
          set -euo pipefail

          IMAGE="cloudrun-ingestor-smoke:${GITHUB_SHA}"
          docker build -f cloudrun_ingestor/Dockerfile -t "${IMAGE}" .

          # Run with dummy config so main.py doesn't exit immediately due to missing env vars.
          CID="$(
            docker run -d -p 18080:8080 \
              -e GCP_PROJECT_ID=dummy \
              -e SYSTEM_EVENTS_TOPIC=dummy \
              -e MARKET_TICKS_TOPIC=dummy \
              -e MARKET_BARS_1M_TOPIC=dummy \
              -e TRADE_SIGNALS_TOPIC=dummy \
              -e INGEST_FLAG_SECRET_ID=dummy \
              "${IMAGE}"
          )"
          cleanup() { docker rm -f "${CID}" >/dev/null 2>&1 || true; }
          trap cleanup EXIT

          # Fail the build if gunicorn (container) exits early.
          sleep 5
          if ! docker ps -q --no-trunc | grep -q "${CID}"; then
            echo "ERROR: cloudrun_ingestor container exited early (gunicorn boot failure)." >&2
            docker logs "${CID}" || true
            exit 1
          fi

          # Optional: ensure HTTP is accepting connections.
          curl -fsS --max-time 2 --retry 10 --retry-connrefused http://localhost:18080/ >/dev/null || {
            echo "ERROR: cloudrun_ingestor did not become reachable on HTTP." >&2
            docker logs "${CID}" || true
            exit 1
          }

          docker stop "${CID}" >/dev/null

      - name: Pub/Sub contract gate (Python envelope vs TS shared types)
        shell: bash
        run: |
          set -euo pipefail
          python3 -m unittest -q tests.test_pubsub_envelope_contract_gate

